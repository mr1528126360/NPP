{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41dbfbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0+cu113 True\n",
      "0.15.0\n",
      "11.3\n",
      "MSVC 192930137\n"
     ]
    }
   ],
   "source": [
    "# 检查torch的安装以及gpu的使用\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# 检查MMAction2的安装\n",
    "import mmaction\n",
    "print(mmaction.__version__)\n",
    "\n",
    "# 检查mmcv的安装\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c54217e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configs/recognition/swin/swin_base_patch244_window877_kinetics400_1k.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15281\\anaconda3\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: checkpoints/swin_base_patch244_window877_kinetics400_1k.pth\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import inference_recognizer, init_recognizer\n",
    "\n",
    "# 选择tsn对应的配置文件\n",
    "config = 'configs/recognition/swin/swin_base_patch244_window877_kinetics400_1k.py'\n",
    "# 加载上面下载的checkpoint文件\n",
    "checkpoint =  'checkpoints/swin_base_patch244_window877_kinetics400_1k.pth'\n",
    "# 初始化模型\n",
    "print(config)\n",
    "model = init_recognizer(config, checkpoint, device='cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36bb4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "# Function to read and randomly split a txt file\n",
    "def read_and_split_txt(file_path, test_size=0.2):\n",
    "    # Read the txt file into a pandas DataFrame\n",
    "    data = pd.read_csv(file_path, delimiter=\",\", header=None)\n",
    "    \n",
    "    # Randomly shuffle the DataFrame\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # Split the data into features and target variable\n",
    "    X = data  # Assuming the last column is the target variable\n",
    "    y = data.iloc[:, -1]\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Example usage\n",
    "file_path = './video_data2/all.csv'\n",
    "X_train, X_test, y_train, y_test = read_and_split_txt(file_path)\n",
    "X_train.to_csv('./video_data2/cu/train.txt', index=False, header=False, sep=' ')\n",
    "X_test.to_csv('./video_data2/cu/val_file.txt', index=False, header=False, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87122a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='SwinTransformer3D',\n",
      "        patch_size=(2, 4, 4),\n",
      "        embed_dim=128,\n",
      "        depths=[2, 2, 18, 2],\n",
      "        num_heads=[4, 8, 16, 32],\n",
      "        window_size=(8, 7, 7),\n",
      "        mlp_ratio=4.0,\n",
      "        qkv_bias=True,\n",
      "        qk_scale=None,\n",
      "        drop_rate=0.0,\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.3,\n",
      "        patch_norm=True),\n",
      "    cls_head=dict(\n",
      "        type='I3DHead',\n",
      "        in_channels=1024,\n",
      "        num_classes=3,\n",
      "        spatial_type='avg',\n",
      "        dropout_ratio=0.5),\n",
      "    test_cfg=dict(average_clips='prob', max_testing_views=4))\n",
      "checkpoint_config = dict(interval=10)\n",
      "log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/swin_base_patch244_window877_kinetics400_1k.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "dataset_type = 'VideoDataset'\n",
      "data_root = './video_data2/train_video/'\n",
      "data_root_val = './video_data2/val_video/'\n",
      "ann_file_train = './video_data2/train.txt'\n",
      "ann_file_val = './video_data2/val_file.txt'\n",
      "ann_file_test = './video_data2/val_file.txt'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
      "train_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(type='SampleFrames', clip_len=16, frame_interval=2, num_clips=1),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Flip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=16,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=16,\n",
      "        frame_interval=2,\n",
      "        num_clips=4,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 224)),\n",
      "    dict(type='ThreeCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=2,\n",
      "    workers_per_gpu=4,\n",
      "    val_dataloader=dict(videos_per_gpu=1, workers_per_gpu=1),\n",
      "    test_dataloader=dict(videos_per_gpu=1, workers_per_gpu=1),\n",
      "    train=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='./video_data2/train.txt',\n",
      "        data_prefix='./video_data2/train_video/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=16,\n",
      "                frame_interval=2,\n",
      "                num_clips=1),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Flip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='./video_data2/val_file.txt',\n",
      "        data_prefix='./video_data2/val_video/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=16,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='./video_data2/val_file.txt',\n",
      "        data_prefix='./video_data2/val_video/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=16,\n",
      "                frame_interval=2,\n",
      "                num_clips=4,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 224)),\n",
      "            dict(type='ThreeCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]))\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "optimizer = dict(\n",
      "    type='AdamW',\n",
      "    lr=7.8125e-06,\n",
      "    betas=(0.9, 0.999),\n",
      "    weight_decay=0.05,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            absolute_pos_embed=dict(decay_mult=0.0),\n",
      "            relative_position_bias_table=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            backbone=dict(lr_mult=0.1))))\n",
      "lr_config = dict(\n",
      "    policy='CosineAnnealing',\n",
      "    min_lr=0,\n",
      "    warmup='linear',\n",
      "    warmup_by_epoch=True,\n",
      "    warmup_iters=2.5)\n",
      "total_epochs = 50\n",
      "work_dir = './tutorial_exps'\n",
      "find_unused_parameters = False\n",
      "fp16 = None\n",
      "optimizer_config = dict(\n",
      "    type='DistOptimizerHook',\n",
      "    update_interval=8,\n",
      "    grad_clip=None,\n",
      "    coalesce=True,\n",
      "    bucket_size_mb=-1,\n",
      "    use_fp16=True)\n",
      "omnisource = False\n",
      "seed = 40\n",
      "gpu_ids = range(1, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "# 获得tsn对应的配置文件cfg\n",
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/recognition/swin/swin_base_patch244_window877_kinetics400_1k.py')\n",
    "# 修改数据集类型和各个文件路径\n",
    "cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = './video_data2/train_video/'\n",
    "cfg.data_root_val = './video_data2/val_video/'\n",
    "cfg.ann_file_train = './video_data2/train.txt'\n",
    "cfg.ann_file_val = './video_data2/val_file.txt'\n",
    "cfg.ann_file_test = './video_data2/val_file.txt'\n",
    "\n",
    "\n",
    "cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = './video_data2/val_file.txt'\n",
    "cfg.data.test.data_prefix = './video_data2/val_video/'\n",
    "\n",
    "cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = './video_data2/train.txt'\n",
    "cfg.data.train.data_prefix = './video_data2/train_video/'\n",
    "cfg.data.train.data_prefix = './video_data2/train_video/'\n",
    "\n",
    "cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = './video_data2/val_file.txt'\n",
    "cfg.data.val.data_prefix = './video_data2/val_video/'\n",
    "\n",
    "# 这里用于确认是否使用到omnisource训练\n",
    "cfg.setdefault('omnisource', False)\n",
    "# 修改cls_head中类别数为3\n",
    "cfg.model.cls_head.num_classes = 3\n",
    "# 使用预训练好的tsn模型\n",
    "cfg.load_from = 'checkpoints/swin_base_patch244_window877_kinetics400_1k.pth'\n",
    "# 设置工作目录\n",
    "cfg.work_dir = './tutorial_exps'\n",
    "\n",
    "# 由于是单卡训练，修改对应的lr\n",
    "#cfg.data.videos_per_gpu = cfg.data.videos_per_gpu // 16\n",
    "cfg.data.videos_per_gpu = 2\n",
    "cfg.optimizer.lr = cfg.optimizer.lr / 8 / 16\n",
    "#设置epoches\n",
    "cfg.total_epochs = 50\n",
    "# 设置存档点间隔减少存储空间的消耗\n",
    "cfg.checkpoint_config.interval = 10\n",
    "# 设置日志打印间隔减少打印时间\n",
    "cfg.log_config.interval = 5\n",
    "\n",
    "# 固定随机种子使得结果可复现\n",
    "cfg.seed = 40\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1,2)\n",
    "\n",
    "# 打印所有的配置参数\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da3c44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "import os\n",
    "\n",
    "# Get a list of all files in the current directory\n",
    "files_in_directory = os.listdir()\n",
    "filtered_files = [file for file in files_in_directory if file.endswith(\".pt\")]\n",
    "\n",
    "# Loop through the list and remove each file\n",
    "for file in filtered_files:\n",
    "    os.remove(file)\n",
    "    #print(f\"Removed {file}\")\n",
    "# 构建数据集\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "# 构建动作识别模型\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "# 创建工作目录并训练模型\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate= True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
